# Capstone Project
Final Project for Data Science Practicum through UCLA Extension, Summer 2020

## Background
This project offered an opportunity to complete a data science project independetly - from data collection all the way through model analysis - with the guidance on an industry professional. Under normal circumstances, a random company sponsors the Data Science Practicum course at UCLA Extension, and provides the data and goal for a capstone project. Given the whirlwind of Covid, however, this partnership was not possible; instead, I found my own large, extremely messy dataset and pretended as though I were a consultant for an imaginary Movie Rating Company. 

## Task
Find or gather a large, messy dataset, clean and impute missing values, and generate models using various machine learning techniques to classify or regress your chosen label based on the features. Do so in the language of your choice, and condense all code and findings into a final markdown file, preferably via jupyter notebook. Present our findings in no fewer than 15 minutes and no more than 20 minutes. 


## Summary of Project
I collected data from Kaggle, which was in turn compiled from Amazon's IMDB website. Upon familiarizing myself with the data, I arbitrarily decided the goal to be to predict movie rating, which techincally was a discrete variable but became *quasi* continouos after grouping on the mean rating for each movie to condense 26 million rows of redundant movie ratings into roughly 45,000 unique values. After merging several dataframes together on various foreign keys using Pandas, I cleaned columns where possible, such as creating dummy variables from strings or reading dictionary values into categorical variables, and dropped columns when necessary. Fortunately, I had few NaN values once the extension cleaning process was completed, but still chose to use Python's new AutoImpute package to assess the distribution of the missing values and maintain as much variance as possible in the imputed data. Finally, I used several machine learning libraries available on scikit-learn for Python, such as SGD, Random Forest, and XGBoost, to maximize my R squared and minimize MSE for movie rating. Sadly, my highest R squared was only about 27%, meaning my models only explained about 27% of the variance presented by the predictors, though this was to be expected. A little research informed me that the art to predicting rating is subtle, and generally not housed in the data available in my dataset.  

The final report reads a working markdown file might. It shows all code, for the purposes of showing my pretend employer (and real teacher) exactly what work was required to achieve the final results. Obviously, this style would not be used in a formal pitch or presentation setting, but got the job done here. In the future, I would have added more data to my dataset by directly from the IMDB website, and merged on any of the four foreign keys available to me. Careful planning at this stage could easilt increase R squared at no cost to MSE. 
